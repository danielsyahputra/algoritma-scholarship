---
title: 'Classification 1 : In-class materials'
author: "David"
date: "`r format(Sys.Date(), '%B %e, %Y')`"
output:
  html_document:
    theme: cosmo
    highlight: tango
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: false
    df_print: paged
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
# clear-up the environment
rm(list = ls())

# chunk options
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  fig.align = "center",
  comment = "#>"
)
options(scipen = 9999)

# libraries
library(readr)
library(tidyverse)
```

# Course Map

<center>

```{r, echo=FALSE}
knitr::include_graphics("img/mindmapc1.png")
```

</center>

# ML: Classification 1

Dalam machine learning dan statistik, **classification** / klasifikasi
adalah bentuk pendekatan supervised learning untuk memprediksi **label**
dari suatu data dengan tipe **kategorikal**.

**Contoh prediksi:**\
- Spam/no spam?\
- Loan default/no default?\
- Customer churn/non churn?\
- ...\
- Yes/no?\
- 1/0? (Positive/Negative?)

non churn churn

karyawan A : peluang untuk churn brp? 0.6 - \> churn

0 hingga 1

range tebakan kita Regression : \[-inf, inf\] classification : \[0, 1\]

# Introduction to (Binary) Classification using Logistic Regression

Tujuan dari logistik regression adalah dengan menggunakan model regresi
linier untuk memprediksi probability(yang dapat digunakan untuk
klasifikasi).

## Linear Regression vs Logistic Regression

<center>

```{r, echo=FALSE}
knitr::include_graphics("img/download.png")
```

</center>

### Probability v.s. Linear Regression

Ide dari logistic regression mulanya berangkat dari model linear
regression. Bedanya:\
- **Linear regression:** digunakan untuk memprediksi angka kontinyu
dengan range `-Inf to Inf`\
- **Logistic regression:** digunakan untuk memprediksi probability
dengan range: `0 to 1`

Range regression: -Inf to Inf\
Range probability: 0 to 1

### Probability

Pada dasarnya, ketika kita melakukan klasifikasi, kita akan menghitung
**peluang**.

$$P(yes) = \frac{n(yes)}{n(yes) + n(no)}$$

Case study: Saat H-2 Lebaran, terdapat 100 penerbangan di Soekarno-Hatta
airport, dari 100 penerbangan tersebut, terdapat 20 penerbangan delay.
Berapakah probability suatu penerbangan delay di Soekarno-Hatta?

```{r}
p_delay <- 20/100
p_delay
```

Peluang penerbangan tidak delay

```{r}
p_no_delay <- (100-20)/100
p_no_delay
```

range dari probability 0 to 1 -inf to inf

### Odds

Odds adalah bentuk lain dari peluang yang memiliki rumus sebagai berikut
$\frac{p}{(1-p)}$ dimana `p` adalah peluang suatu kejadian terjadi. Odds
adalah **peluang kejadian terjadi/peluang kejadian tidak terjadi**.

$$Odds(yes) = \frac{P(yes)}{1-P(yes)}$$ Berapakah odds penerbangan
terbang tepat waktu?

```{r}
# peluang tepat waktu dibandingkan dengan peluang delay
p_no_delay/(1 - p_no_delay)
```

Interpetasi:

> Penerbangan di soetta 4 kali lebih mungkin berangkat tepat waktu
> dibanding delay

```{r}
p_delay / (1- p_delay)
```

odds = 1 odds \> 1 kemungkinan lebih odds \< 1 lebih tidak mungkin

Berapa range nilai dari odds?

```{r}
# max
peluang <- 0.99
peluang/(1-peluang)


# min
peluang <- 0
peluang/(1-peluang)
```

-   Probability: 0 0.5 1
-   Odds : 0 to inf

```{r}
# logit(0.4)
```

### Log of Odds

Log of odds adalah nilai odds yang dilogaritmikan (logit(p) =
log(\frac{p}{1-p})) :

Berapakah log(odds) dari penerbangan tepat waktu?

```{r}
log(4)
```

range: -inf to inf

**Nilai log of odds tidak bisa diinterpretasikan**. Log of Odds
dihasilkan oleh **Logistic Regression**. Nilai log of odds dapat
dikembalikan ke bentuk odds dan peluang sehingga dapat digunakan untuk
klasifikasi.

*Discussion:* Bagaimana cara untuk mengembalikan nilai log(odds) ke
peluang?

log(odds) -> odds

```{r}
exp(1.386294)
```

odds -> probability

$$p = \frac{odds}{1+odds}$$

```{r}
4/(1+4)
```

### Logit dan Inverse Logit

Terdapat cara lain untuk mengubah peluang ke log of odds dengan fungsi
`logit()` dan mengubah log of odds ke peluang dengan fungsi
`inv.logit()`. Fungsi `inv.logit()` yang biasa disebut *sigmoidal
logistic function*.

```{r}
library(gtools)
logit(0.8) #mengubah probability menjadi log of odds
inv.logit(1.386294) # mengubah log of odds menjadi probability
```

## Logistic Regression dengan `glm()`

Business question:

Sebagai seorang analis di suatu universitas, anda ditugaskan untuk
memprediksi apakah siswa akan lulus dengan honors(cumlaude) atau tidak.

Read data `sample.csv`

```{r}
honors <- read.csv("data_input/sample.csv") %>% 
          select(-femalexmath)
head(honors)
```

Deskripsi variabel:

-   `female`: gender of student (1 for female, 0 for male)

-   `read`: score in reading test

-   `write`: score in writing test

-   `math`: score in math test

-   `hon`: status of graduating in honors (1 for honors, 0 for not
    honors)

-   cek missing value

```{r}
colSums( is.na(honors))
```

cek struktur data, kolom mana yang memiliki tipe data yang salah

```{r}
str(honors)
```

ubah tipe data yang masih salah

```{r}
# cara dplyr
honors <- honors %>% 
  mutate(female = as.factor(female), 
         hon = as.factor(hon))

# cara base
honors$female <- as.factor(honors$female)
honors$hon <- as.factor(honors$hon)

```

```{r}
summary(honors)
```

Buatlah sebuah model tanpa prediktor

untuk membuat model logistic regression bisa menggunakan fungsi `glm()`
terdapat 3 paramater yang kita gunakan yaitu formula : tempat
mendefinisikan target dan predictor (y\~x) data : data yang digunakan
untuk membuat model family : gunakan "binomial" bila ingin menggunakan
logistic regression pada pemodelan ini

target variabel tidak harus bernilai 0 atau 1, bisa dalam bentk lainnya
seperti "yes" dan "no"

```{r}
model_null <- glm(formula = hon ~ 1, data = honors, family = "binomial")
summary(model_null)
```

y = B0 + B1*X1 +B2*X2 + .... y = B0 : tanpa predictor B0 = -1.1255
probability, odds, log of odds?log of odds

Kenapa didapati nilai koefisien sebesar -1.1255?

```{r}
library(gtools)
table(honors$hon)
```

```{r}
# peluang
p_0 <- 151/(151+49)
p_0
```

```{r}
# log of odds dari tidak dapat honor
logit(p_0) # mengubah peluang menjadi log of odds
```

```{r}
p_1 <- 49/(151+49)
p_1
logit(p_1)
```

**Interpretasi:**

> Nilai intercept -1.1255, yakni merupakan nilai log of odds dari target
> variabel (hon). Log of odds tidak dapat diinterpretasikan. Untuk
> interpretasi, nilai log of odds kita ubah ke odds/peluang.

```{r}
# log of odds -> odds 
odds <- exp(-1.1255)
odds
# log of odds -> prob
inv.logit(-1.1255)
```

> Kejadian student lulus dengan predikat honors 0.32 KALI lebih mungkin
> dibandingkan student lulus tanpa predikat honors.

> Peluang student lulus dengan predikat honors adalah 0.24.

> Student lebih mungkin untuk lulus tanpa predikat honors.

**Note:**\
Nilai log of odds tidak dapat diinterpretasi, untuk menginterpretasikan
nilai *log(odds)*:\
- dikembalikan ke odds dengan `exp()`\
- dikembalikan ke p dengan inv.logit

### Model dengan 1 prediktor kategorik

Buatlah sebuah model dengan 1 prediktor, yakni female

```{r}
model_f <- glm(formula = hon ~ female, data = honors, family = "binomial")  
summary(model_f)
```

Y = B0 + B1*X1 hon = -1.4709 + 0.5928* female

-   yang diubah menjadi odds adalah koefisien, supaya nilai koefisien
    bisa di interpretasikan

```{r}
# log of odds -> odds
exp(0.5928)
```

> Kemungkinan perempuan memperoleh honors adalah 1.8 kali lebih mungkin
> bila dibandingkan pria mendapatkan honor

-   yang di ubah menjadi probability adalah hasilnya (y)

```{r}
hon  <-  -1.4709 + 0.5928 * 1
hon # log of odds
```

```{r}
inv.logit(hon) # peluang 
```

peluang dia mendapatkan honors 0.29. bisa dibilang dia diprediksi tidak
mendapatkan honor

Coefficient **Female** menjelaskan log of odds dari *female mendapat
honor* dibandingkan *male mendapat honor*.

**Bagaimana cara menginterpretasikan koefisien female?**

```{r}
# lakukan eksponen pada koef female

```

> Kemungkinan perempuan memperoleh honors dibandingkan adalah 1.8 kali
> lebih mungkin bila dibandingkan pria mendapatkan honor

**\[OPTIONAL\] Bagaimana cara mendapatkan nilai log of odds female?**

```{r}
table(honors = honors$hon, female = honors$female)
```

1.  Hitung peluang untuk female dan male

```{r}
# peluang female dapat honors
honf <- 32/(77+32)
# peluang male dapat honors
honm <- 17/(17+74)

```

2.  Hitung nilai odds female dan male

```{r}
# odds
oddsf <- honf/(1-honf)
oddsm <- honm/(1-honm)
```

3.  Hitung nilai odds ratio

```{r}
oddsf/oddsm
```

4.  Hitung nilai log of odds ratio

```{r}
log(oddsf/oddsm)
```

**Question**

Bila diketahui seorang siswi bernama Ajeng (female) masuk kedalam kelas
berapa peluang dia mendapatkan penghargaan ketika lulus (honor = 1)?

```{r}

```

### Model dengan 1 prediktor numerik

Buat model untuk memprediksi `honors` berdasarkan nilai `math`:

```{r}
model_math <- glm(formula = hon ~ math, data = honors, family = "binomial")
summary(model_math)
```

hon = -9.79394 + 0.15634 \* math

**Interpretasi:**

```{r}
# log of odds -> odds
exp(0.15634)
```

> Setiap kenaikan 1 nilai pada math maka odds seseorang mendapatkan
> honor naik sebesar 1.17 KALI.

**Intercept**: Log of odds dari student yang nilai mathnya 0.

**Math**: Peningkatan log of odds setiap peningkatan 1 nilai di math.

contoh:

`hon = -9.79394 + 0.15634 * math`

Student ke-1 memiliki nilai math 52, student kedua 53. Hitung
masing-masing log of oddsnya, berapa selisihnya?

```{r}
# log of odds
hon52 <- -9.79394 + 0.15634 * 52
hon53 <- -9.79394 + 0.15634 * 53

hon53 - hon52
```

```{r}
exp(hon53)/exp(hon52)
```

berapa peluang siswa yang mendapatkan honors bila siswa tersebut
mendapatkan nilai math 52

```{r}
inv.logit(hon52)
```

Peluang siswa mendapatkan honors bila diketahui nilai math nya sebesar
52 adalah 0.15. bisa kita bilang siswa tersebut tidak mendapatkan honors

```{r}
summary(model_math)
summary(model_f)
```

> Siswa dengan nilai 53 akan 1.17 KALI lebih mungkin mendapatkan honors
> dibandingkan yang mendapat nilai 52.

> Memiliki nilai math yang lebih tinggi meningkatkan peluang student
> mendapatkan honors.

-------------------End of Day 2--------------------------

## Dive deeper

Buatlah model yang dapat memprediksi seseorang akan lulus dengan
predikat honors berdasarkan gender dan nilai math nya, kemudian jawablah
pertanyaan berikut:

1.  Interpretasi dari coefficient yang peroleh

2.  Wulan memperoleh nilai math sebesar 60, berapa peluang Wulan
    mendapatkan honors?

3.  Handoyo memperoleh nilai math sebesar 70, berapa peluang Handoyo
    mendapatkan honors?

```{r}
model_gm <- glm(formula = hon ~ math + female, data = honors,family = "binomial")
summary(model_gm)
```

Jawab:

1.  Interpretasi coefficient

```{r}
exp(coef(model_gm))
```

> coefficient math:

Setiap kenaikan 1 nilai pada math maka odds seseorang mendapatkan honor
naik sebesar 1.17 KALI dibandingkan nilai dibawahnya.

> coefficient female

Kemungkinan perempuan memperoleh honors adalah 2.62 kali lebih mungkin
bila dibandingkan pria mendapatkan honor

2.  Wulan memperoleh nilai math sebesar 60, berapa peluang Wulan
    mendapatkan honors?

```{r}
wulan_score <- -10.8060  + 0.1642*60+ 0.9653 *1
```

3.  Handoyo memperoleh nilai math sebesar 70, berapa peluang Handoyo
    mendapatkan honors?

```{r}
handoyo_score <- -10.8060  + 0.1642*70+ 0.9653 *0
```

```{r}
prob_dd <- inv.logit(c(wulan_score, handoyo_score))
prob_dd
```

convert peluang ke kategorik

```{r}
ifelse(prob_dd > 0.5, "1","0")
```

### Null & Residual Deviance

Deviance is defined as the difference of likelihoods between the fitted
model and the perfect (saturated) model.

-   **Null deviance**: Null deviance menunjukkan error ketika model
    tanpa prediktor
-   **Residual deviance**: residual deviance menunjukkan error ketika
    model dengan seluruh prediktor
-   **Num of iteration** : iterasi/perulangan untuk mendapatkan model
    terbaik

Ambilah model dengan nilai residual deviance paling rendah.

```{r}

```

```{r}
model_null$deviance
model_f$deviance
model_math$deviance
model_gm$deviance
```

Reference: <https://bookdown.org/egarpor/SSS2-UC3M/logreg-deviance.html>

Selanjutnya kita akan coba membuat model honors menggunakan semua
variabel prediktor:

```{r, eval = FALSE}
model_all <- glm(formula = hon ~ ., data = honors,family = "binomial")
summary (model_all)
```

```{r}
exp(coef(model_all))
```

Untuk cek proporsi nilai write terhadap variabel honors

```{r}
table(honors = honors$hon, female = honors$write)
```

> Dari tabel di atas, dapat disimpulkan bahwa ketika nilai write \< 61,
> maka dia not honors, sisanya honors. Variabel write ini membagi kelas
> target secara sempurna, variabel write ini disebut perfect separator.

## Perfect Separation

**Perfect Separation** adalah sebuah kondisi dimana ada 1 variabel yang
dapat memisahkan kelas target secara sempurna. pada kasus ini adalah
nilai write dapat memisahkan kelas honor dengan baik (kalau nilai write
lebih dari 60 maka mendapatkan honor).

ada 2 hal yg bisa kita lakukan

1.  Jika kasus seperti ini kita terima, tidak usah membuat machine
    learning cukup ifelse saja

2.  Jika kasus ini tidak kita terima, maka jgn gunakan variabel ini
    sebagai predictor

untuk mendeteksi ada atau tidaknya perfect separation:

1.  Dilihat dari koefisien dari model yg dibuat, apabila ada nilai koef
    yang sangat besar dan P-value dari semua variabel cenderung tidak
    signifikan maka ada kondisi perfect separator dalam model kita.

2.  Nilai pada Residual Deviances mendekati 0

Membuat model tanpa variabel write

```{r}
mod_all_w <- glm(formula = hon ~ . -write, data = honors,family = "binomial")
summary(mod_all_w)
```

Interpretasi koefisien female

```{r}
# ubah dalam bentuk odds
exp(mod_all_w$coefficients[2])

```

> Nilai odds ratio pada female 2.664, artinya ketika seseorang adalah
> female, ia lebih mungkin 2.664 KALI menjadi honors dibanding ketika
> dia male. Dengan catatan, variabel prediktor lain konstan

### AIC

AIC mengestimasi jumlah informasi yang hilang dari suatu model. Semakin
kecil AIC, semakin baik model.

```{r, eval=FALSE}
model_null$aic
model_f$aic
model_math$aic
mod_all_w$aic
```

## Assumption

Logistic Regression menganut 3 asumsi:

-   **Multicollinearity**: antar prediktor tidak saling berpengaruh
-   **Independence of Observations**: antar observasi independent
-   **Linearity of Predictor & Log of Odds**: nilai prediktor
    berkorelasi linear dengan log of odds

Berikut data penerbangan pesawat dalam `flight_sm.csv`:

```{r}
flights <- read.csv("data_input/flight_sm.csv")
str(flights)
```

1.  Buat model `flight.model` untuk memprediksi `DepDel15` berdasarkan
    `Month` + `DayofWeek`, kemudian tampilkan hasil summary

```{r}
flight.model <- glm(formula = DepDel15 ~ Month + DayofWeek, data = flights, family = "binomial")
summary(flight.model)
```

2.  Interpretasi koefisien tiap variabel!

```{r}
exp(flight.model$coefficients[2])
exp(flight.model$coefficients[3])
```

> Nilai odds kurang dari 1 artinya pada bulan berikutnya akan
> memperkecil kemungkinan untuk delay

> Nilai odds kurang dari 1 artinya pada hari berikutnya akan memperkecil
> kemungkinan untuk delay

3.  apakah terdapat multicolinearity pada model?

```{r}
library(car)

vif(flight.model)
```

Jawab : Multicoliearity apabila terdapat nilai vif yang \> 10. Jadi,
dapat disimpulkan bahwa tidak terdapat mulicolinearity pada model.

Perhatikan kembali pada bagian interpretasi. Apakah dalam kasus ini
(delay flight) variabel month dan DayofWeekrelevant digunakan sebagai
predictor?

```{r}
flights <- flights %>% 
  mutate(DayofWeek = as.factor(DayofWeek),
         Month = as.factor(Month))

flight.model <- glm(formula = DepDel15 ~ Month + DayofWeek, data = flights, family = "binomial")

summary(flight.model)
```

# Classification Workflow

1.  Read Data
2.  Data Wrangling
3.  EDA
4.  Cross Validation
5.  Data Pre-Processing
6.  Build Model
7.  Predict
8.  Evaluation
9.  Model Tuning
10. Final Model

# Credit Risk Analysis

## 1. Read data

```{r}
loans <- read.csv("data_input/loan2017Q4.csv")
head(loans)
```

Descriptions:

-   `initial_list_status`: Either `w` (whole) or `f` (fractional). This
    variable indicates if the loan was a whole loan or fractional loan.
    For background: Some institutional investors have a preference to
    purchase loans in their entirety to obtain legal and accounting
    treatment specific to their situation - with the added benefit of
    "instant funding" to borrowers\
-   `purpose`: Simplified from the original data; One of: `credit_card`,
    `debt_consolidation`, `home_improvement`, `major_purchase` and
    `small_business`\
-   `int_rate`: Interest rate in percentages\
-   `installment`: Monthly payment owed by the borrower\
-   `annual_inc`: Self-reported annual income provided by the borrower /
    co-borrowers during application\
-   `dti`: A ratio of the borrower's total monthly debt payments on
    his/her total obligations to the self-reported monthly income\
-   `verification_status`: is the reported income verified, not
    verified, or if the income source was verified\
-   `grade`: software-assigned loan grade\
-   `revol_bal`: total credit revolving balance (in the case of credit
    card, it refers to the portion of credit card spending that goes
    unpaid at the end of a billing cycle)\
-   `inq_last_12m`: number of credit inquiries in the last 12 months\
-   `delinq_2yrs`: number of 30+ days past-due incidences of delinquency
    in the borrower's credit file for the past 2 years\
-   `home_ownership`: one of `MORTGAGE`, `OWN` and `RENT`\
-   `not_paid`: 0 for fully-paid loans, 1 for charged-off, past-due /
    grace period or defaulted\
-   `log_inc`: log of `annual_inc`\
-   `verified`: 0 for "Not verified" under `verification_status`, 1
    otherwise\
-   `grdCtoA`: 1 for a `grade` of A, B or C, 0 otherwise

## 2. Data Wrangling

```{r}
# cek struktur data
str(loans)

```

```{r}
summary(loans)
```

-   Apa target variabel dari data diatas?

-   variabel apa yang belum memiliki tipe data yang tepat?

> -   initial_list_status
>
> -   purpose
>
> -   home_ownership
>
> -   not_paid
>
> -   verified
>
> -   grdCtoA
>
> Ubah jadi factor semua

-   **Indikasi multicollinearity**

Cek adanya indikasi multicollinearity berdasarkan pengetahuan bisnis
(lihat deskripsi kolom).

-   verified
-   grCtoA
-   annual_inc

Notes: membuang log_inc, verification status, grade karena sudah
dijelaskan oleh annual_inc, verified, dan grdCtoA.

```{r}
# lakukan data cleansing 
loans_clean <- loans %>% 
  select(-c(log_inc, verification_status, grade)) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(verified = as.factor(verified),
         grdCtoA = as.factor(grdCtoA),
         not_paid = as.factor(not_paid))

str(loans_clean)
```

## 3. Eksploratory Data Analysis

-   **Check missing value**

```{r}
colSums(is.na(loans_clean))

```

-   **Analisis persebaran data**

```{r}
# cek sebaran data
summary(loans_clean)
```

**Discussion:**

Dilihat dari hasil delinq_2yrs dominan berada di nilai 0, apakah kita
akan tetap memasukannya ke dalam model?

```{r}
# Zero variance, deling_2yrs ga dipakai
table(loans_clean$delinq_2yrs)
```

-   **Check Class Imbalance**

```{r}

loans_clean <- loans_clean %>% 
  select(-delinq_2yrs)

head(loans_clean)
```

Proporsi yang seimbang penting agar model klasifikasi mempelajari
karakteristik kelas positif maupun negatif secara seimbang, tidak dari
satu kelas saja. Hal ini mencegah model dari *hanya baik memprediksi 1
kelas saja*.

Proporsi yang imbalance umumnya 90/10 atau 95/5.

```{r}
table(loans_clean$not_paid)
```

#### Cross Validation

Jika kita ingin melakukan sebuah prediksi, maka kita tidak disarankan
melihat nilai error pada data yang digunakan untuk melatih model, karena
itu hanya menunjukkan bahwa model dapat memprediksi data lama tetapi
belum tentu dapat memprediksi data baru. Data yang digunakan untuk
melatih model kita sebut dengan `data train`, sedangkan data yang
digunakan untuk mengevaluasi model disebut dengan `data test`.

Berikut beberapa kondisi yang dapat terjadi pada model:

-   Overfitting: Model terlalu bagus dalam mengikuti pola di data train,
    menyebabkan model kurang mampu memprediksi data baru
-   Underfitting: Model kurang bisa menangkap pola di data train
-   Optimum: Model mampu mengikui pola data train tetapi masih memiliki
    kemampuan yang baik dalam memprediksi data baru

Untuk mengevaluasi model dan melihat kemampuannya memprediksi data baru,
data kita bagi menjadi 2: data train dan data test. Proses ini kita
sebut dengan `cross-validation`.

Misalkan saya menggunakan 80% dari seluruh data yang saya miliki menjadi
data train dan sisanya akan digunakan sebagai data test.

Analogi:

-   100 soal
-   80 soal saya pakai untuk belajar (data train)
-   20 soal saya pakai untuk ujian (data test)

tujuan dari cross validation adalah untuk mengetahui seberapa baik model
yg sudah kita buat.

```{r}
RNGkind(sample.kind = "Rounding")
set.seed(417)


```

NOTE: Proporsi 0.8/0.2 tidak mutlak, tergantung kebutuhan kita.

```{r}
# re-check class imbalance


```

proporsi kelas yang balance penting untuk data train karena kita akan
melatih model menggunakan data train.

#### Build Model

Membuat model berdasarkan business knowledge dan arahan yang sudah ada:

```{r }
creditrisk <- 

summary(creditrisk)
```

Interpretasi:

Mengubah log off odds ke nilai odds

```{r}
exp(coef(creditrisk))
```

Interpretasi untuk parameter:

> purpose small business: Kemungkinan nasabah dengan purpose small
> business 2.53 KALI lebih mungkin untuk not paid dibandingkan dengan
> purpose credit card, dengan catatan variabel lainnya memiliki nilai
> yang sama

> int_rate: Setiap kenaikan int_rate sebesar 1 unit maka kecenderungan
> nasabah untuk gagal bayar naik sebesar 1.01 kali dengan catatan
> variabel lainnya konstan

Lakukan feature selection menggunakan stepwise

```{r}
# logistic regression juga dapat menggunakan step
creditrisk2 <- 
```

#### Predict

`predict(model, newdata, type)`

type memiliki 2 nilai yaitu `response` dan `link`:

-   `type = link`: memberikan output berupa nilai `log of odds`
-   `type = response`: memberikan output berupa nilai peluang

```{r}
# predict data test menggunakan model yang sudah dibuat

```

```{r}
# ubah probability menjadi label 

```

-------------------End of Day 2--------------------------
